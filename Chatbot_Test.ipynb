{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbot Test.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwC3DrL7nFTp",
        "colab_type": "text"
      },
      "source": [
        "## <pre>                               <b> Model Testing and Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "347UnDxpC7_3",
        "colab_type": "text"
      },
      "source": [
        "# Import all necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWyZIMpTx-9l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bdf25b79-3e29-4697-e4da-a3a94f7bdd0c"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers import Dense, Input, Embedding\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from collections import Counter\n",
        "import nltk\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV2cjFTH6fzn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b5d1edc3-4549-467d-db4d-d2fe25979649"
      },
      "source": [
        "import keras\n",
        "import nltk\n",
        "import numpy as np\n",
        "import sklearn\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A7ey0zh6lqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RAND_STATE=np.random.seed(42)\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 10\n",
        "GLOVE_EMBEDDING_SIZE = 100\n",
        "HIDDEN_UNITS = 256\n",
        "MAX_INPUT_SEQ_LENGTH = 40\n",
        "MAX_TARGET_SEQ_LENGTH = 40\n",
        "MAX_VOCAB_SIZE = 10000\n",
        "DATA_SET_NAME = '/content/drive/My Drive/Chatbot/Chatbot'\n",
        "DATA_PATH = '/content/drive/My Drive/Chatbot/Chatbot/movie_lines_cleaned.txt'\n",
        "GLOVE_MODEL = \"/content/drive/My Drive/glove.twitter.27B.100d.txt\"\n",
        "WHITELIST = 'abcdefghijklmnopqrstuvwxyz1234567890?.,'\n",
        "WEIGHT_FILE_PATH = '/content/drive/My Drive/Chatbot/Chatbot/word-glove-weights.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaA-slSS6qC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def in_white_list(_word):\n",
        "    return set(_word) <= set(WHITELIST)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELHAdHr5697b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_glove_vector():\n",
        "    _word2embedding = {}\n",
        "    file = open(GLOVE_MODEL, mode='rt', encoding='utf8')\n",
        "    for line in file:\n",
        "        splitLine = line.split()\n",
        "        if in_white_list(splitLine[0]):\n",
        "            _word2embedding[splitLine[0]] = np.array([float(val) for val in splitLine[1:]])\n",
        "    file.close()\n",
        "    return _word2embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U4xqUGGDdLc",
        "colab_type": "text"
      },
      "source": [
        "## <i>Defining chatbot function to get the required output "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfefI3i-6z6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CornellChatBot(object):\n",
        "    model = None\n",
        "    encoder_model = None\n",
        "    decoder_model = None\n",
        "    target_word2idx = None\n",
        "    target_idx2word = None\n",
        "    max_decoder_seq_length = None\n",
        "    max_encoder_seq_length = None\n",
        "    num_decoder_tokens = None\n",
        "    word2embedding = None\n",
        "\n",
        "    def __init__(self):\n",
        "        self.word2embedding = load_glove_vector()\n",
        "        print(len(self.word2embedding))\n",
        "        print(self.word2embedding['start'])\n",
        "\n",
        "        self.target_word2idx = np.load( DATA_SET_NAME + '/word-glove-target-word2idx.npy',allow_pickle=True).item()\n",
        "        self.target_idx2word = np.load( DATA_SET_NAME + '/word-glove-target-idx2word.npy',allow_pickle=True).item()\n",
        "        context = np.load( DATA_SET_NAME + '/word-glove-context.npy',allow_pickle=True).item()\n",
        "        self.max_encoder_seq_length = context['encoder_max_seq_length']\n",
        "        self.max_decoder_seq_length = context['decoder_max_seq_length']\n",
        "        self.num_decoder_tokens = context['num_decoder_tokens']\n",
        "\n",
        "        encoder_inputs = Input(shape=(None, GLOVE_EMBEDDING_SIZE), name='encoder_inputs')\n",
        "        encoder_lstm = LSTM(units=HIDDEN_UNITS, return_state=True, name=\"encoder_lstm\")\n",
        "        encoder_outputs, encoder_state_h, encoder_state_c = encoder_lstm(encoder_inputs)\n",
        "        encoder_states = [encoder_state_h, encoder_state_c]\n",
        "\n",
        "        decoder_inputs = Input(shape=(None, GLOVE_EMBEDDING_SIZE), name='decoder_inputs')\n",
        "        decoder_lstm = LSTM(units=HIDDEN_UNITS, return_sequences=True, return_state=True, name='decoder_lstm')\n",
        "        decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "        decoder_dense = Dense(self.num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
        "        decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "        self.model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "\n",
        "        self.model.load_weights(WEIGHT_FILE_PATH)\n",
        "        self.model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "\n",
        "        self.encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "        decoder_state_inputs = [Input(shape=(HIDDEN_UNITS,)), Input(shape=(HIDDEN_UNITS,))]\n",
        "        decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_state_inputs)\n",
        "        decoder_states = [state_h, state_c]\n",
        "        decoder_outputs = decoder_dense(decoder_outputs)\n",
        "        self.decoder_model = Model([decoder_inputs] + decoder_state_inputs, [decoder_outputs] + decoder_states)\n",
        "\n",
        "    def reply(self, input_text):\n",
        "        input_seq = []\n",
        "        input_emb = []\n",
        "        for word in nltk.word_tokenize(input_text.lower()):\n",
        "            if not in_white_list(word):\n",
        "                continue\n",
        "            emb = np.zeros(shape=GLOVE_EMBEDDING_SIZE)\n",
        "            if word in self.word2embedding:\n",
        "                emb = self.word2embedding[word]\n",
        "            input_emb.append(emb)\n",
        "        input_seq.append(input_emb)\n",
        "        input_seq = pad_sequences(input_seq, self.max_encoder_seq_length)\n",
        "        states_value = self.encoder_model.predict(input_seq)\n",
        "        target_seq = np.zeros((1, 1, GLOVE_EMBEDDING_SIZE))\n",
        "        target_seq[0, 0, :] = self.word2embedding['start']\n",
        "        target_text = ''\n",
        "        target_text_len = 0\n",
        "        terminated = False\n",
        "        while not terminated:\n",
        "            output_tokens, h, c = self.decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "            sample_token_idx = np.argmax(output_tokens[0, -1, :])\n",
        "            sample_word = self.target_idx2word[sample_token_idx]\n",
        "            target_text_len += 1\n",
        "\n",
        "            if sample_word != 'start' and sample_word != 'end':\n",
        "                target_text += ' ' + sample_word\n",
        "\n",
        "            if sample_word == 'end' or target_text_len >= self.max_decoder_seq_length:\n",
        "                terminated = True\n",
        "\n",
        "            target_seq = np.zeros((1, 1, GLOVE_EMBEDDING_SIZE))\n",
        "            if sample_word in self.word2embedding:\n",
        "                target_seq[0, 0, :] = self.word2embedding[sample_word]\n",
        "\n",
        "            states_value = [h, c]\n",
        "        return target_text.strip()\n",
        "\n",
        "    def test_run(self):\n",
        "        print(self.reply('What do you know'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CecbPeMDxka",
        "colab_type": "text"
      },
      "source": [
        "## Creating object for class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4nHpbzb7Feu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "b8d748b7-6ac4-4a48-aefb-f2005b7d4028"
      },
      "source": [
        "bot = CornellChatBot()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "559648\n",
            "[-0.17989   0.22297   0.47938  -0.71227  -0.45818   1.0285    0.32394\n",
            " -0.060409 -0.37064   0.3051   -0.14261  -0.56449  -4.5301    0.54817\n",
            " -0.85281  -0.086907 -0.28587   0.86288  -0.28724  -0.65113  -0.97384\n",
            "  0.11036  -0.05808  -0.034859 -0.36309   0.19478   0.17636  -0.32154\n",
            " -0.22864  -0.11961  -0.044675  0.54424  -0.25474   0.21692   0.5004\n",
            "  0.21677   0.33958  -0.27821   0.58674   0.013013 -0.98293   0.5214\n",
            "  0.11687  -0.10702   0.1903    0.25038  -0.24482  -0.068194 -0.23054\n",
            "  0.24936   0.081091 -0.71015   0.050871 -0.16209   0.49785  -0.44498\n",
            " -0.79807  -0.1008    0.80597   0.18716  -0.65218  -0.27916   0.23074\n",
            " -0.35599  -0.18894   0.36532   0.74004  -0.29412   0.90441   0.067676\n",
            " -0.19106   0.59315   0.058992  0.53448   0.32551   0.060201  0.28332\n",
            "  0.026973 -0.079146 -0.40832   1.3507   -0.1911   -0.23131  -0.37369\n",
            "  0.32181   0.10459  -0.11756   0.028256  0.27408  -0.289    -0.21644\n",
            "  0.17697  -0.23683   0.15782  -0.22889   0.26629  -0.28217   0.29003\n",
            " -0.032464 -0.55074 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIIkrZDMoFBt",
        "colab_type": "text"
      },
      "source": [
        "### <b>Testing the bot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBiG_-BP9DDY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3fff6631-4805-4fa3-becb-3e7fe727ac9b"
      },
      "source": [
        "bot.test_run()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i do n't\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spPBI6DKEGEL",
        "colab_type": "text"
      },
      "source": [
        "## Using Flask to interact with the bot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15sjGd-j_jjz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chatbot_html = \"\"\"\n",
        "<style type=\"text/css\">\n",
        "#log p { margin: 5px; font-family: sans-serif; align:center;}</style>\n",
        "<div id=\"log\"\n",
        "     style=\"box-sizing: border-box;\n",
        "            width: 600px;\n",
        "            height: 32em;\n",
        "            border: 1px grey solid;\n",
        "            padding: 2px;\n",
        "            overflow: scroll;\">\n",
        "</div>\n",
        "<input type=\"text\" id=\"typehere\" placeholder=\"type here!\"\n",
        "       style=\"box-sizing: border-box;\n",
        "              width: 600px;\n",
        "              margin-top: 5px;\">\n",
        "<script>\n",
        "function paraWithText(t) {\n",
        "    let tn = document.createTextNode(t);\n",
        "    let ptag = document.createElement('p');\n",
        "    ptag.appendChild(tn);\n",
        "    return ptag;\n",
        "}\n",
        "document.querySelector('#typehere').onchange = async function() {\n",
        "    let inputField = document.querySelector('#typehere');\n",
        "    let val = inputField.value;\n",
        "    inputField.value = \"\";\n",
        "    let resp = await getResp(val);\n",
        "    let objDiv = document.getElementById(\"log\");\n",
        "    objDiv.appendChild(paraWithText('ðŸ˜€: ' + val));\n",
        "    objDiv.appendChild(paraWithText('ðŸ¤–: ' + resp));\n",
        "    objDiv.scrollTop = objDiv.scrollHeight;\n",
        "};\n",
        "async function colabGetResp(val) {\n",
        "    let resp = await google.colab.kernel.invokeFunction(\n",
        "        'notebook.get_response', [val], {});\n",
        "    return resp.data['application/json']['result'];\n",
        "}\n",
        "async function webGetResp(val) {\n",
        "    let resp = await fetch(\"/response.json?sentence=\" + \n",
        "        encodeURIComponent(val));\n",
        "    let data = await resp.json();\n",
        "    return data['result'];\n",
        "}\n",
        "</script>\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYT6M7T5oSIb",
        "colab_type": "text"
      },
      "source": [
        "## Creating a localhost to run chatbot\n",
        "             OR\n",
        "### Go below to use Tkinter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z91-jkrv_jqh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "fbe3bd10-036b-470b-cdde-719e67dc75c2"
      },
      "source": [
        "from flask import Flask, request, jsonify\n",
        "app = Flask(__name__)\n",
        "@app.route(\"/response.json\")\n",
        "def response():\n",
        "    sentence = request.args['sentence']\n",
        "    return jsonify(\n",
        "        {'result': bot.reply(sentence)})\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return chatbot_html + \"<script>let getResp = webGetResp;</script>\"\n",
        "app.run()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7-NiIoTEPJX",
        "colab_type": "text"
      },
      "source": [
        "## Using Tkinter to create a chatbot like visuals\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PwW0uyX_kTT",
        "colab_type": "text"
      },
      "source": [
        "    ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pj1TkNtW-VNB",
        "colab_type": "code",
        "colab": {},
        "cellView": "code"
      },
      "source": [
        "#@title Default title text\n",
        "#Creating GUI with tkinter\n",
        "import tkinter\n",
        "from tkinter import *\n",
        "\n",
        "def send():\n",
        "    msg = EntryBox.get(\"1.0\",'end-1c').strip()\n",
        "    EntryBox.delete(\"0.0\",END)\n",
        "\n",
        "    if msg != '':\n",
        "        ChatLog.config(state=NORMAL)\n",
        "        \n",
        "        ChatLog.insert(END, \"YOU: \" + msg + '\\n\\n')\n",
        "        ChatLog.config(foreground=\"#442265\", font=(\"Verdana\", 12 ))\n",
        "\n",
        "        res = model.reply(msg)\n",
        "        ChatLog.insert(END, \"BOT: \" + res + '\\n\\n')\n",
        "\n",
        "        ChatLog.config(state=DISABLED)\n",
        "        ChatLog.yview(END)\n",
        "\n",
        "\n",
        "base = Tk()\n",
        "base.title(\"Hello\")\n",
        "base.geometry(\"400x500\")\n",
        "base.resizable(width=FALSE, height=FALSE)\n",
        "\n",
        "#Create Chat window\n",
        "ChatLog = Text(base, bd=0, bg=\"white\", height=\"8\", width=\"50\", font=\"Arial\",)\n",
        "\n",
        "ChatLog.config(state=DISABLED)\n",
        "\n",
        "#Bind scrollbar to Chat window\n",
        "scrollbar = Scrollbar(base, command=ChatLog.yview, cursor=\"heart\")\n",
        "ChatLog['yscrollcommand'] = scrollbar.set\n",
        "\n",
        "#Create Button to send message\n",
        "SendButton = Button(base, font=(\"Verdana\",12,'bold'), text=\"Send\", width=\"12\", height=5,\n",
        "                    bd=0, bg=\"blue\", activebackground=\"#3c9d9b\",fg='#ffffff',\n",
        "                    command= send )\n",
        "\n",
        "#Create the box to enter message\n",
        "EntryBox = Text(base, bd=0, bg=\"white\",width=\"29\", height=\"5\", font=\"Arial\", borderwidth=5)\n",
        "#EntryBox.bind(\"<Return>\", send)\n",
        "\n",
        "\n",
        "#Place all components on the screen\n",
        "scrollbar.place(x=376,y=6, height=386)\n",
        "ChatLog.place(x=6,y=6, height=386, width=370)\n",
        "EntryBox.place(x=128, y=401, height=90, width=265)\n",
        "SendButton.place(x=6, y=401, height=90)\n",
        "\n",
        "base.mainloop()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfOVG94h-vM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}