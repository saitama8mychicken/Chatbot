{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdV5h1HTE9Yn",
        "colab_type": "text"
      },
      "source": [
        "# <b>Building a Chatbot from Scratch "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQzzHdFVFDNX",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "##### <b>In this project we will build a chatbot from scratch using the corenell University's Movie Dialogue corpus.\n",
        "##### <i><b>We will be using a deep learning based architecture with the main components as a lstm based encoder and decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vCiHh8_R7Fu",
        "colab_type": "code",
        "outputId": "f3036adf-2875-4b5a-f454-7d6d77f00f15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.python.keras.layers.recurrent import LSTM\n",
        "from tensorflow.keras.layers import Dense, Input, Embedding, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from collections import Counter\n",
        "import nltk\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import load_model, model_from_json\n",
        "import keras\n",
        "import nltk\n",
        "import numpy as np\n",
        "import sklearn\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQwBSNVIfdyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJQdgKyUFUJX",
        "colab_type": "text"
      },
      "source": [
        "Download the glove model available at https://nlp.stanford.edu/projects/glove/\n",
        "\n",
        "Specification : Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased, 25d, 50d, 100d, & 200d vectors, 1.42 GB download): glove.twitter.27B.zip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6E5noJ6rFt-6",
        "colab_type": "text"
      },
      "source": [
        "you can download it with 'wget' or can directly put the embedding zip file inside 'embedding_data' folder and unzip it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc0Lh3e5kTC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ! curl -O http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9gx3IF9TMeh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RAND_STATE=np.random.seed(42)\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 10\n",
        "GLOVE_EMBEDDING_SIZE = 100\n",
        "HIDDEN_UNITS = 256\n",
        "MAX_INPUT_SEQ_LENGTH = 40\n",
        "MAX_TARGET_SEQ_LENGTH = 40\n",
        "MAX_VOCAB_SIZE = 10000\n",
        "DATA_SET_NAME = '/content/drive/My Drive/Chatbot/Chatbot'\n",
        "DATA_PATH = '/content/drive/My Drive/Chatbot/Chatbot/movie_lines_cleaned.txt'\n",
        "GLOVE_MODEL = \"/content/drive/My Drive/glove.twitter.27B.100d.txt\"\n",
        "WHITELIST = 'abcdefghijklmnopqrstuvwxyz1234567890?.,'\n",
        "WEIGHT_FILE_PATH =  DATA_SET_NAME + '/word-glove-weights.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L0id60gTZPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def in_white_list(_word):\n",
        "    return set(_word) <= set(WHITELIST)\n",
        "#   '''Check if the characters in the words are whitelisted'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAtGlqNiGCHA",
        "colab_type": "text"
      },
      "source": [
        "Load the glove word embedding in to a dictionary where the **key** is a unique **word token** and the **value** is a **d** dimension vector "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lyg8iSWUGEpy",
        "colab_type": "text"
      },
      "source": [
        "# Test-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NLGSWg0TlBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_glove_vector():\n",
        "    _word2embedding = {}\n",
        "    file = open(GLOVE_MODEL, mode='rt', encoding='utf8')\n",
        "    for line in file:\n",
        "        '''write here. write your code to load the data in to the dictionary\n",
        "        make sure the value is a numpy array of size 100\n",
        "        max  3 to 6 lines of code'''\n",
        "        words = line.strip().split()\n",
        "        word = words[0]\n",
        "        embedding = np.array(words[1:], dtype=np.float32)\n",
        "        _word2embedding[word] = embedding        \n",
        "    file.close()\n",
        "    return _word2embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTv8TDMfToBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2embedding = load_glove_vector()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtCcKuxDTtpw",
        "colab_type": "code",
        "outputId": "061fc73d-51af-483a-8d11-9ac2bffc1cfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "assert len(word2embedding.keys())==1193514\n",
        "for key in word2embedding.keys():\n",
        "    try:\n",
        "        assert len(word2embedding[key])==100\n",
        "    except AssertionError:\n",
        "        print (key,len(word2embedding[key]))  "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.32053 99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VXmlxmSN0N_",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSSzAupfUOF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_counter = Counter()\n",
        "lines = open(DATA_PATH, 'rt', encoding='utf8').read().split('\\n')\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "prev_words = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gu1Cq9yRWXg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for line in lines:\n",
        "    next_words = [w.lower() for w in nltk.word_tokenize(line)]\n",
        "    if len(next_words) > MAX_TARGET_SEQ_LENGTH:\n",
        "        next_words = next_words[0:MAX_TARGET_SEQ_LENGTH]\n",
        "    if len(prev_words) > 0:\n",
        "        input_texts.append(prev_words)\n",
        "        target_words = next_words[:]\n",
        "        target_words.insert(0, 'start')\n",
        "        target_words.append('end')\n",
        "        for w in target_words:\n",
        "            target_counter[w] += 1\n",
        "        target_texts.append(target_words)\n",
        "    prev_words = next_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kqhOyRYOMEw",
        "colab_type": "text"
      },
      "source": [
        "Filter the conversations till max word length and convert the dialogues pairs into input text and target texts. Put **start** and **end** token to recognise the beginning and end of the sentence token.\n",
        "\n",
        "## <b>Let's see some of the training examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fALhlI2WnfR",
        "colab_type": "code",
        "outputId": "4e03e5a9-e20b-46bf-8734-c387c4083ec8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "for idx, (input_words, target_words) in enumerate(zip(input_texts, target_texts)):\n",
        "    if idx > 10:\n",
        "        break\n",
        "    print([input_words, target_words])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['they', 'do', 'not', '!'], ['start', 'they', 'do', 'to', '!', 'end']]\n",
            "[['they', 'do', 'to', '!'], ['start', 'i', 'hope', 'so', '.', 'end']]\n",
            "[['i', 'hope', 'so', '.'], ['start', 'she', 'okay', '?', 'end']]\n",
            "[['she', 'okay', '?'], ['start', 'let', \"'s\", 'go', '.', 'end']]\n",
            "[['let', \"'s\", 'go', '.'], ['start', 'wow', 'end']]\n",
            "[['wow'], ['start', 'okay', '--', 'you', \"'re\", 'gon', 'na', 'need', 'to', 'learn', 'how', 'to', 'lie', '.', 'end']]\n",
            "[['okay', '--', 'you', \"'re\", 'gon', 'na', 'need', 'to', 'learn', 'how', 'to', 'lie', '.'], ['start', 'no', 'end']]\n",
            "[['no'], ['start', 'i', \"'m\", 'kidding', '.', 'you', 'know', 'how', 'sometimes', 'you', 'just', 'become', 'this', '``', 'persona', \"''\", '?', 'and', 'you', 'do', \"n't\", 'know', 'how', 'to', 'quit', '?', 'end']]\n",
            "[['i', \"'m\", 'kidding', '.', 'you', 'know', 'how', 'sometimes', 'you', 'just', 'become', 'this', '``', 'persona', \"''\", '?', 'and', 'you', 'do', \"n't\", 'know', 'how', 'to', 'quit', '?'], ['start', 'like', 'my', 'fear', 'of', 'wearing', 'pastels', '?', 'end']]\n",
            "[['like', 'my', 'fear', 'of', 'wearing', 'pastels', '?'], ['start', 'the', '``', 'real', 'you', \"''\", '.', 'end']]\n",
            "[['the', '``', 'real', 'you', \"''\", '.'], ['start', 'what', 'good', 'stuff', '?', 'end']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df40O1vROaHt",
        "colab_type": "text"
      },
      "source": [
        "### Create two dictionaries \n",
        "<ol>\n",
        "<li>target_word2id\n",
        "<li>target_id2word\n",
        "</ol>\n",
        "and save it as NumPy file format in the disk.\n",
        "<p>\n",
        "<strong>NOTE:</strong> The ids should start from 1 beacause <strong>0</strong> is reserved for <strong>'unknown'</strong> tokens.\n",
        "Make sure you cosider only the <strong>most common</strong> tokens with <strong>MAX_VOCAB_SIZE</strong> defined above.\n",
        "\n",
        "Most common refers to tokens with higher frequency. \n",
        "</p>\n",
        "<strong>Help:</strong>\n",
        "<ol>\n",
        "<li>Use the target_counter which have the token counts.  \n",
        "<li>Use target_counter.most_common(MAX_VOCAB_SIZE) to filter common tokens\n",
        "    </ol>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bF7tQ4dvWnkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_word2idx = dict()\n",
        "'''create a target word to id dictionary called target_word2idx.\n",
        "2 to 3 lines '''\n",
        "for idx, word in enumerate(target_counter.most_common(MAX_VOCAB_SIZE)):\n",
        "    target_word2idx[word[0]] = idx + 1\n",
        "    \n",
        "if 'unk' not in target_word2idx:\n",
        "    target_word2idx['unk'] = 0\n",
        "\n",
        "# '''create a target to id diilter the conversations till max word length and convert the dialogues pairs into input text and target texts. Put **start** and **end** token to recognise the beginning and end of the sentence token.\n",
        "\n",
        "## Let's see some of the training examplesctionary called target_idx2word . Approx ~1 line'''\n",
        "target_idx2word = {value: key for key, value in target_word2idx.items() }\n",
        "\n",
        "num_decoder_tokens = len(target_idx2word)\n",
        "\n",
        "np.save( DATA_SET_NAME + '/word-glove-target-word2idx.npy', target_word2idx)\n",
        "np.save( DATA_SET_NAME + '/word-glove-target-idx2word.npy', target_idx2word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnq9cE12OuQF",
        "colab_type": "text"
      },
      "source": [
        "## CHECK 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPGYEDlpWnrb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert len (target_word2idx.keys())==len (target_idx2word.keys())==MAX_VOCAB_SIZE+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCbrtw2GOrVk",
        "colab_type": "text"
      },
      "source": [
        "# <b>Prepare the input data with embedding</b>\n",
        "The input data is a list of lists \n",
        "<ol>\n",
        "<li> First list is a list of sentences\n",
        "<li> Each sentence is a list of words\n",
        " </ol>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mboaY4CCWnpH",
        "colab_type": "code",
        "outputId": "a56a67b1-ea28-4510-eb3b-7df1b28a8fda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input_texts_word2em = []\n",
        "encoder_max_seq_length = 0\n",
        "decoder_max_seq_length = 0\n",
        "\n",
        "for input_words, target_words in zip(input_texts, target_texts):\n",
        "    encoder_input_wids = []\n",
        "    for w in input_words:\n",
        "        '''enter your code here.\n",
        "        '''\n",
        "        embedding = np.zeros(shape=GLOVE_EMBEDDING_SIZE)\n",
        "        if w in word2embedding:\n",
        "            embedding = word2embedding[w]\n",
        "        encoder_input_wids.append(embedding)\n",
        "        \n",
        "\n",
        "    input_texts_word2em.append(encoder_input_wids)\n",
        "    encoder_max_seq_length = max(len(encoder_input_wids), encoder_max_seq_length)\n",
        "    decoder_max_seq_length = max(len(target_words), decoder_max_seq_length)\n",
        "\n",
        "context = dict()\n",
        "context['num_decoder_tokens'] = num_decoder_tokens\n",
        "context['encoder_max_seq_length'] = encoder_max_seq_length\n",
        "context['decoder_max_seq_length'] = decoder_max_seq_length\n",
        "\n",
        "print(context)\n",
        "np.save( DATA_SET_NAME + '/word-glove-context.npy', context)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'num_decoder_tokens': 10001, 'encoder_max_seq_length': 40, 'decoder_max_seq_length': 42}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgIasMAZWni4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for input_text,input_text_embed in zip (input_texts,range(len(input_texts_word2em))):\n",
        "    assert (len(input_text)==len(input_texts_word2em[input_text_embed]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzkOdzPpO37H",
        "colab_type": "text"
      },
      "source": [
        "## GENERATE TRAINING DATA PER BATCH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVQApmpZO4HL",
        "colab_type": "text"
      },
      "source": [
        "generate_batch takes input embedding data (input_word2em_data) and target text data (target_texts) and returns trainable X and Y.\n",
        "X is a list of [X1,X2]\n",
        "where \n",
        "X1 is encoder_input_data_batch( which is created by putting the word embedding(glove vector) of the input tokens) padded in to a shape of (BATCH_SIZE, encoder_max_seq_length, GLOVE_EMBEDDING_SIZE)\n",
        "\n",
        "X2 is decoder_input_data_batch which is created by putting the word embedding(glove vector) of the target_words tokens and padding it to a shape of (BATCH_SIZE, decoder_max_seq_length, GLOVE_EMBEDDING_SIZE)\n",
        "\n",
        "Y is decoder_target_data_batch which is in shape of (BATCH_SIZE, decoder_max_seq_length, num_decoder_tokens)\n",
        "which signifies for each target token text  in the batch we have an option of any token from the vocabularu to be the next predicted word "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afNd4tUXW_4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batch(input_word2em_data, output_text_data):\n",
        "    num_batches = len(input_word2em_data) // BATCH_SIZE\n",
        "    while True:\n",
        "        for batchIdx in range(0, num_batches):\n",
        "            start = batchIdx * BATCH_SIZE\n",
        "            end = (batchIdx + 1) * BATCH_SIZE\n",
        "            encoder_input_data_batch = pad_sequences(input_word2em_data[start:end], encoder_max_seq_length, dtype='float32', padding='post', truncating='post')\n",
        "            decoder_target_data_batch = np.zeros(shape=(BATCH_SIZE, decoder_max_seq_length, num_decoder_tokens))\n",
        "            decoder_input_data_batch = np.zeros(shape=(BATCH_SIZE, decoder_max_seq_length, GLOVE_EMBEDDING_SIZE))\n",
        "            '''Fill your code here. 5 to 10 lines'''\n",
        "            for index, target_words in enumerate(output_text_data[start:end]):\n",
        "                for idx, word in enumerate(target_words):\n",
        "                    word2index = target_word2idx['unk']  # default unknown\n",
        "                    if word in target_word2idx:\n",
        "                        word2index = target_word2idx[word]\n",
        "                    if word in word2embedding:\n",
        "                        decoder_input_data_batch[index, idx, :] = word2embedding[word]\n",
        "                    if idx > 0:\n",
        "                        decoder_target_data_batch[index, idx - 1, word2index] = 1\n",
        "            yield [encoder_input_data_batch, decoder_input_data_batch], decoder_target_data_batch\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIySnGEgX82R",
        "colab_type": "text"
      },
      "source": [
        "## **Check-4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZdMdv79X5lh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93ca18f8-7e93-462a-8a23-f85371ac7343"
      },
      "source": [
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(input_texts_word2em, target_texts, test_size=0.2, random_state=42)\n",
        "train_gen = generate_batch(Xtrain, Ytrain)\n",
        "for i,j in train_gen:\n",
        "    assert i[0].shape==(BATCH_SIZE,context['encoder_max_seq_length'],GLOVE_EMBEDDING_SIZE)\n",
        "    assert i[1].shape==(BATCH_SIZE,context['decoder_max_seq_length'],GLOVE_EMBEDDING_SIZE)\n",
        "    assert j.shape==(BATCH_SIZE,context['decoder_max_seq_length'],context['num_decoder_tokens'])\n",
        "\n",
        "print ('Test Case 4 Passes!')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Case 4 Passes!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8I5cglmYKO-",
        "colab_type": "text"
      },
      "source": [
        "# Model Architecture "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUCF3GKNYR8x",
        "colab_type": "text"
      },
      "source": [
        "# The Model architecture is explined in the diagram below "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ru6LZhq1YWw9",
        "colab_type": "text"
      },
      "source": [
        "# Test-5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5MmYY1MYg2d",
        "colab_type": "text"
      },
      "source": [
        "<ol>\n",
        "<li> Step 1: Use a LSTM encoder to get input words encoded in the form of (encoder outputs, encoder hidden state, encoder context) from input words\n",
        "<li> Step 2:  Use a LSTM decoder to get target words encoded in the form of (decoder outputs, decoder hidden state, decoder context) from target words. Use encoder hidden states and encoder context (represents input memory) as initial state .\n",
        "<li> Step 3: Use a dense layer to predict the next token out of the vocabulary given decoder output generated by Step 2.\n",
        "<li> Step 4: Use loss ='categorical_crossentropy' and optimizer='rmsprop'\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkvOwAwceIyo",
        "colab_type": "code",
        "outputId": "82248516-3802-4d92-ca37-0a90859aa230",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "'''write your code here.\n",
        "   create a model object'''\n",
        "\n",
        "#Encoder layers,inputs,outputs\n",
        "encoder_inputs = Input(shape=(None, GLOVE_EMBEDDING_SIZE), name='encoder_inputs')\n",
        "encoder_lstm = LSTM(units=HIDDEN_UNITS, return_state=True, name='encoder_lstm')\n",
        "encoder_outputs, encoder_state_h, encoder_state_c = encoder_lstm(encoder_inputs)\n",
        "encoder_states = [encoder_state_h, encoder_state_c]\n",
        "\n",
        "#Decoder layers - input,output,LSTM,Dense\n",
        "decoder_inputs = Input(shape=(None, GLOVE_EMBEDDING_SIZE), name='decoder_inputs')\n",
        "decoder_lstm = LSTM(units=HIDDEN_UNITS, return_state=True, return_sequences=True, name='decoder_lstm')\n",
        "decoder_outputs, decoder_state_h, decoder_state_c = decoder_lstm(decoder_inputs,\n",
        "                                                                 initial_state=encoder_states)\n",
        "decoder_dense = Dense(units=num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "#model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',metrics=['accuracy'])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MWCL9zpKtBI",
        "colab_type": "code",
        "outputId": "8c32b49f-92b8-409b-95f3-66e15c49df63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_inputs (InputLayer)     [(None, None, 100)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_inputs (InputLayer)     [(None, None, 100)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_lstm (LSTM)             [(None, 256), (None, 365568      encoder_inputs[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder_lstm (LSTM)             [(None, None, 256),  365568      decoder_inputs[0][0]             \n",
            "                                                                 encoder_lstm[0][1]               \n",
            "                                                                 encoder_lstm[0][2]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder_dense (Dense)           (None, None, 10001)  2570257     decoder_lstm[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 3,301,393\n",
            "Trainable params: 3,301,393\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqzFBHTwYoz-",
        "colab_type": "text"
      },
      "source": [
        "## CHECK 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uz8EHtpRE8NM",
        "colab_type": "code",
        "outputId": "9f5a128c-cf71-407b-f7a7-632302b9ef9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png')\n",
        "from IPython.display import Image\n",
        "Image(filename='model.png',height=400,width=400)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 400,
              "height": 400
            }
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5t5zRlMYzlm",
        "colab_type": "text"
      },
      "source": [
        "## <b>Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FC33XmJllWdO",
        "colab_type": "text"
      },
      "source": [
        "### In case model is already trained then load the weights and run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeK5uhwAlTOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # load json and create model\n",
        "# json_file = open('/content/drive/My Drive/Chatbot/Chatbot/colab_model.json', 'r')\n",
        "# load_model_json = json_file.read()\n",
        "# json_file.close()\n",
        "# loaded_model = model_from_json(load_model_json)\n",
        "# # load weights into new model\n",
        "# loaded_model.load_weights(\"/content/drive/My Drive/Chatbot/Chatbot/colab_model.h5\")\n",
        "# print(\"Loaded model from disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1xOZYEqXANC",
        "colab_type": "code",
        "outputId": "22e8cf34-0bf9-4336-97c4-5cd2d9cf091d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "source": [
        "#execution and updation of wt in batches\n",
        "train_gen = generate_batch(Xtrain, Ytrain)\n",
        "test_gen = generate_batch(Xtest, Ytest)\n",
        "\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "train_num_batches = len(Xtrain) // BATCH_SIZE\n",
        "test_num_batches = len(Xtest) // BATCH_SIZE\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "# train model\n",
        "checkpoint = ModelCheckpoint(filepath=WEIGHT_FILE_PATH, save_best_only=True, verbose=1)\n",
        "\n",
        "model.fit_generator(generator=train_gen, steps_per_epoch=train_num_batches,\n",
        "                    epochs=NUM_EPOCHS,\n",
        "                    verbose=1,\n",
        "                    validation_data=test_gen, \n",
        "                    validation_steps=test_num_batches,\n",
        "                    callbacks=[checkpoint])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-20-4357f9aa8f90>:19: Model.fit_generator (from tensorflow.python.keras.engine.training_v1) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/10\n",
            "2435/2435 [==============================] - ETA: 0s - loss: 1.4565 - acc: 0.2480\n",
            "Epoch 00001: val_loss improved from inf to 1.37323, saving model to /content/drive/My Drive/Chatbot/Chatbot/word-glove-weights.h5\n",
            "2435/2435 [==============================] - 686s 282ms/step - loss: 1.4565 - acc: 0.2480 - val_loss: 1.3732 - val_acc: 0.3414\n",
            "Epoch 2/10\n",
            "2435/2435 [==============================] - ETA: 0s - loss: 1.3395 - acc: 0.2696\n",
            "Epoch 00002: val_loss improved from 1.37323 to 1.33903, saving model to /content/drive/My Drive/Chatbot/Chatbot/word-glove-weights.h5\n",
            "2435/2435 [==============================] - 700s 287ms/step - loss: 1.3395 - acc: 0.2696 - val_loss: 1.3390 - val_acc: 0.0942\n",
            "Epoch 3/10\n",
            "2435/2435 [==============================] - ETA: 0s - loss: 1.3128 - acc: 0.3069\n",
            "Epoch 00003: val_loss improved from 1.33903 to 1.32462, saving model to /content/drive/My Drive/Chatbot/Chatbot/word-glove-weights.h5\n",
            "2435/2435 [==============================] - 690s 283ms/step - loss: 1.3128 - acc: 0.3069 - val_loss: 1.3246 - val_acc: 0.0960\n",
            "Epoch 4/10\n",
            "2435/2435 [==============================] - ETA: 0s - loss: 1.2990 - acc: 0.3213\n",
            "Epoch 00004: val_loss improved from 1.32462 to 1.31858, saving model to /content/drive/My Drive/Chatbot/Chatbot/word-glove-weights.h5\n",
            "2435/2435 [==============================] - 688s 283ms/step - loss: 1.2990 - acc: 0.3213 - val_loss: 1.3186 - val_acc: 0.1015\n",
            "Epoch 5/10\n",
            "2435/2435 [==============================] - ETA: 0s - loss: 1.2914 - acc: 0.2077\n",
            "Epoch 00005: val_loss improved from 1.31858 to 1.31703, saving model to /content/drive/My Drive/Chatbot/Chatbot/word-glove-weights.h5\n",
            "2435/2435 [==============================] - 688s 283ms/step - loss: 1.2914 - acc: 0.2077 - val_loss: 1.3170 - val_acc: 0.1041\n",
            "Epoch 6/10\n",
            "2435/2435 [==============================] - ETA: 0s - loss: 1.2882 - acc: 0.2010\n",
            "Epoch 00006: val_loss did not improve from 1.31703\n",
            "2435/2435 [==============================] - 688s 283ms/step - loss: 1.2882 - acc: 0.2010 - val_loss: 1.3181 - val_acc: 0.1134\n",
            "Epoch 7/10\n",
            "2435/2435 [==============================] - ETA: 0s - loss: 1.2842 - acc: 0.2646\n",
            "Epoch 00007: val_loss did not improve from 1.31703\n",
            "2435/2435 [==============================] - 684s 281ms/step - loss: 1.2842 - acc: 0.2646 - val_loss: 1.3192 - val_acc: 0.1001\n",
            "Epoch 8/10\n",
            "2435/2435 [==============================] - ETA: 0s - loss: 1.2817 - acc: 0.2222\n",
            "Epoch 00008: val_loss did not improve from 1.31703\n",
            "2435/2435 [==============================] - 685s 281ms/step - loss: 1.2817 - acc: 0.2222 - val_loss: 1.3174 - val_acc: 0.1068\n",
            "Epoch 9/10\n",
            "2435/2435 [==============================] - ETA: 0s - loss: 1.2806 - acc: 0.2788\n",
            "Epoch 00009: val_loss did not improve from 1.31703\n",
            "2435/2435 [==============================] - 684s 281ms/step - loss: 1.2806 - acc: 0.2788 - val_loss: 1.3185 - val_acc: 0.1118\n",
            "Epoch 10/10\n",
            "2435/2435 [==============================] - ETA: 0s - loss: 1.2789 - acc: 0.1535\n",
            "Epoch 00010: val_loss did not improve from 1.31703\n",
            "2435/2435 [==============================] - 681s 280ms/step - loss: 1.2789 - acc: 0.1535 - val_loss: 1.3206 - val_acc: 0.1045\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0dd45a5be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ38PMkQNS9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IL4gTOagZuBZ",
        "colab_type": "text"
      },
      "source": [
        "## SAVING THE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87edXaRLXALu",
        "colab_type": "code",
        "outputId": "3431e21b-c80d-4e91-accc-9d4424705657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"/content/drive/My Drive/Chatbot/Chatbot/colab_new_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"/content/drive/My Drive/Chatbot/Chatbot/colab_new_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qjlpnn6wl54r",
        "colab_type": "text"
      },
      "source": [
        "# <b>Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srB_jCOGZ2Ck",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**FOR TESTING THE CHATBOT GO TO TEST_CHATBOT. ipynb**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4ss33b-mBHk",
        "colab_type": "text"
      },
      "source": [
        "For predictions go to the test_chatbot.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8NDBU5Hlq0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}